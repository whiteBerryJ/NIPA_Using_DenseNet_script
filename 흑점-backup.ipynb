{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/workspace/user-workspace')\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/workspace/data/.task138/sample_train_space.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# data/.task138/sample_space/AIA2012/{image_file_name}.jpg\n",
    "# data/.task138/sample_space/HMIB2012/{image_file_name}.jpg\n",
    "# data/.task138/sample_train_space.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/workspace/data/.task138/sample_train_space.csv'\n",
    "df = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[df.label == True].index:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.label == True]), len(df[df.label == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_path = []\n",
    "hmib_path = []\n",
    "for i in range(len(df)):\n",
    "    apath = os.path.join('/home/workspace/data/.task138/sample_space/sample/AIA2012', df.AIA.iloc[i])\n",
    "    hpath = os.path.join('/home/workspace/data/.task138/sample_space/sample/HMIB2012/', df.HMIB.iloc[i])\n",
    "    \n",
    "    aia_path.append(apath)\n",
    "    hmib_path.append(hpath)\n",
    "    \n",
    "print(len(aia_path))\n",
    "print(len(hmib_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        return img\n",
    "\n",
    "    except:\n",
    "        print(f'Error: {img_path}')\n",
    "        return np.zeros((256, 256, 3), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img = Image.imread(aia_path[i+5310])\n",
    "    print(img.shape)\n",
    "    print(aia_path[i+5310])\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "# 원래 흑백이미지이기 때문에 shape가 (512,512)인데 이것을 (512,512,3)으로 바꿈\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img = Image.imread(hmib_path[i+5310])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태양의 크기가 안맞음 이방법은 X\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img0 = Image.imread(aia_path[i+5310])\n",
    "    img = Image.imread(hmib_path[i+5310])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "#     plt.imshow(img-img0)\n",
    "    plt.imshow(img0-img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HMIB = 'HMIB2012/' + df.HMIB\n",
    "df.AIA = 'AIA2012/' + df.AIA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.label.iloc[i] == False:\n",
    "        df.label.iloc[i] = '0'\n",
    "    else:\n",
    "        df.label.iloc[i] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input imagedatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = (224,224)\n",
    "batch_size = 32\n",
    "directory = '/home/workspace/data/.task138/sample_space/sample/'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "\n",
    "\n",
    "generator_tra1 = train_datagen.flow_from_dataframe(\n",
    "                                    df,\n",
    "                                    directory,\n",
    "                                    x_col = 'HMIB',\n",
    "                                    y_col = 'label',\n",
    "                                    subset = 'training',\n",
    "                                    target_size = image_size,\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 42)\n",
    "\n",
    "generator_tra2 = train_datagen.flow_from_dataframe(\n",
    "                                    df,\n",
    "                                    directory,\n",
    "                                    x_col = 'AIA',\n",
    "                                    y_col = 'label',\n",
    "                                    subset = 'training',\n",
    "                                    target_size = image_size,\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 42)\n",
    "\n",
    "print(generator_tra1.n)\n",
    "print(generator_tra2.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val1 = train_datagen.flow_from_dataframe(\n",
    "                                    df,\n",
    "                                    directory,\n",
    "                                    x_col = 'HMIB',\n",
    "                                    y_col = 'label',\n",
    "                                    subset = 'validation',\n",
    "                                    target_size = image_size,\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 42)\n",
    "\n",
    "generator_val2 = train_datagen.flow_from_dataframe(\n",
    "                                    df,\n",
    "                                    directory,\n",
    "                                    x_col = 'AIA',\n",
    "                                    y_col = 'label',\n",
    "                                    subset = 'validation',\n",
    "                                    target_size = image_size,\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 42)\n",
    "\n",
    "print(generator_val1.n)\n",
    "print(generator_val2.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_image_generator(gen1, gen2):\n",
    "\n",
    "    while True:\n",
    "        X1, Y = gen1.next()\n",
    "        X2, Y = gen2.next()\n",
    "        \n",
    "        yield [X1,X2], Y  #X1i[1] is the label\n",
    "\n",
    "train_generator = two_image_generator(generator_tra1,generator_tra2)\n",
    "valid_generator = two_image_generator(generator_val1,generator_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature_model - DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model == feature model\n",
    "feature_model = keras.applications.DenseNet201(weights=\"imagenet\", include_top=False)\n",
    "feature_model.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_hmib_features = []\n",
    "train_aia_features = []\n",
    "\n",
    "for i in tqdm(range(generator_tra1.n//batch_size)):\n",
    "    \n",
    "    [x1, x2] , y = train_generator.__next__()\n",
    "    train_labels.extend(y)\n",
    "#     print(x1.shape, x2.shape)  #--> (32, 224, 224, 3) (32, 224, 224, 3)\n",
    "    \n",
    "    feature1, feature2 = feature_model.predict(x1), feature_model.predict(x2)\n",
    "#     print(feature1.shape, feature2.shape) # --> (32, 7, 7, 1920) (32, 7, 7, 1920)\n",
    "    train_hmib_features.extend(feature1)\n",
    "    train_aia_features.extend(feature2)\n",
    "    \n",
    "train_hmib_features = np.array(train_hmib_features)\n",
    "train_aia_features = np.array(train_aia_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(train_hmib_features.shape)\n",
    "print(train_aia_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = []\n",
    "valid_hmib_features = []\n",
    "valid_aia_features = []\n",
    "\n",
    "for i in tqdm(range(generator_val1.n//batch_size)):\n",
    "    \n",
    "    [x1, x2] , y = valid_generator.__next__()\n",
    "    valid_labels.extend(y)\n",
    "#     print(x1.shape, x2.shape)  #--> (32, 224, 224, 3) (32, 224, 224, 3)\n",
    "    \n",
    "    feature1, feature2 = feature_model.predict(x1), feature_model.predict(x2)\n",
    "#     print(feature1.shape, feature2.shape)  #--> (32, 7, 7, 1920) (32, 7, 7, 1920)\n",
    "    valid_hmib_features.extend(feature1)\n",
    "    valid_aia_features.extend(feature2)\n",
    "    \n",
    "valid_hmib_features = np.array(valid_hmib_features)\n",
    "valid_aia_features = np.array(valid_aia_features)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "print(valid_hmib_features.shape)\n",
    "print(valid_aia_features.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('./blackspot_models_and_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hft_path = './blackspot_models_and_features/train_features_hmib.npy'\n",
    "aft_path = './blackspot_models_and_features/train_features_aia.npy'\n",
    "tlabel_path = './blackspot_models_and_features/train_labels.npy'\n",
    "\n",
    "hfv_path = './blackspot_models_and_features/valid_features_hmib.npy'\n",
    "afv_path = './blackspot_models_and_features/valid_features_aia.npy'\n",
    "vlabel_path = './blackspot_models_and_features/valid_labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(hf_path,train_hmib_features )\n",
    "np.save(af_path,train_aia_features )\n",
    "np.save(label_path,train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(hfv_path,valid_hmib_features )\n",
    "np.save(afv_path,valid_aia_features )\n",
    "np.save(vlabel_path,valid_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hmib_features = np.load(hft_path)\n",
    "train_aia_features = np.load(aft_path)\n",
    "train_labels = np.load(tlabel_path)\n",
    "\n",
    "print(\"complete train data\")\n",
    "\n",
    "valid_hmib_features = np.load(hfv_path)\n",
    "valid_aia_features = np.load(afv_path)\n",
    "valid_labels = np.load(vlabel_path)\n",
    "\n",
    "print(\"complete valid data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_input_model(feature_model, num_outputs=1):\n",
    "    \n",
    "    inputs1 = Input(shape=feature_model.output.shape[1:])\n",
    "    inputs2 = Input(shape=feature_model.output.shape[1:])\n",
    "    merged = Concatenate(axis=1)([inputs1, inputs2])\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(merged)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    \n",
    "    outputs = Dense(num_outputs, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2],\n",
    "                 outputs = outputs)\n",
    "    \n",
    "    init_lr = 4e-4\n",
    "    opt = Adam(lr=init_lr)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss= 'binary_crossentropy',\n",
    "                  metrics='accuracy')\n",
    "    \n",
    "    \n",
    "    return model\n",
    "# feature_model.output.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_multi_input_model(feature_model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"./blackspot_models_and_features/best_model\"\n",
    "\n",
    "cp = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=5, \n",
    "                                   min_lr=2e-6)\n",
    "es = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=50) \n",
    "callbacks_list = [cp, es, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 200\n",
    "\n",
    "history = model.fit(x =[train_hmib_features, train_aia_features],\n",
    "                    y = train_labels,\n",
    "                    validation_data = ([valid_hmib_features, valid_aia_features], valid_labels),\n",
    "                    epochs = initial_epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = callbacks_list\n",
    "                    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_multi_input_model(feature_model)\n",
    "# 가중치 로드\n",
    "\n",
    "model2.load_weights(weight_path)\n",
    "\n",
    "# 모델 평가\n",
    "print(model2.evaluate([valid_hmib_features, valid_aia_features], valid_labels))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('./blackspot_models_and_features/model_best_blackspot_binary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3= load_model('./blackspot_models_and_features/model_best_blackspot_binary.h5')\n",
    "print(model3.evaluate([valid_hmib_features, valid_aia_features], valid_labels))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetuning(model, num_outputs=2):\n",
    "    \n",
    "    inputs1 = Input(shape=(224, 224,3))\n",
    "    inputs2 = Input(shape=(224, 224,3))\n",
    "    \n",
    "    x1 = feature_model(inputs1)\n",
    "    x2 = feature_model(inputs2)\n",
    "    outputs = model([x1,x2])\n",
    "\n",
    "    model_fine = Model(inputs=[inputs1,inputs2],\n",
    "                 outputs = outputs)\n",
    "    init_lr = 1e-6\n",
    "    opt = Adam(lr=init_lr)\n",
    "    model_fine.compile(optimizer=opt, \n",
    "                    loss= 'binary_crossentropy',\n",
    "                    metrics='accuracy')\n",
    "        \n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning 모델 구축\n",
    "finetune = build_finetuning(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model.trainable = True\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(feature_model.layers))\n",
    "fine_tune_at = 350\n",
    "\n",
    "for layer in feature_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "\n",
    "finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"./blackspot_models_and_features/bes_model_finetuned\"\n",
    "\n",
    "cp = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=10, \n",
    "                                   min_lr=2e-7)\n",
    "es = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=50) \n",
    "callbacks_list = [cp, es, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 50\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = finetune.fit(train_generator,\n",
    "                    validation_data = valid_generator,\n",
    "                    epochs = total_epochs,\n",
    "                    steps_per_epoch = generator_tra1.n//batch_size,\n",
    "                    validation_steps = generator_val1.n//batch_size,\n",
    "                    initial_epoch= history.epoch[-1],\n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = callbacks_list\n",
    "                    )\n",
    "\n",
    "finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('DanseNet_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = build_finetuning(model3)\n",
    "\n",
    "# 가중치 로드\n",
    "model4.load_weights(weight_path)\n",
    "\n",
    "# 모델 평가\n",
    "model4.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('./blackspot_models_and_features/model_best_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
